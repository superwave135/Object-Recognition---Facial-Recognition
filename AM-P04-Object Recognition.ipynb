{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Name: Tan Ngiap Chuan Alvin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning - Practicum 04 - Object Recognition\n",
    "\n",
    "**Topics covered**: Apply two classifers, logistic regression and random forest to identify subjects from facial images.\n",
    "\n",
    "**Deliverables**:\n",
    "- Complete the tasks as detailed in this document.\n",
    "- You are allowed to use scikit-learn packages.\n",
    "\n",
    "**Objectives**:  \n",
    "The objective of image recognition is to identify and portray, as a unique gray level (or color), the features occurring in an image in terms of the object on the ground. Image recognition is perhaps the most important part of digital image analysis. This tutorial will help you get familiarize with image object recognition using classifier. After completing it,  you will know:\n",
    "- How to read image files.\n",
    "- How to apply classifiers, e.g. logistic regression, random forest, for object recognition from images.\n",
    "\n",
    "---\n",
    "Import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from PIL import Image                                      # read image\n",
    "from sklearn.linear_model import LogisticRegression        # logistic regression classifier\n",
    "from sklearn.ensemble import RandomForestClassifier        # random forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "[olivettifaces](https://scikit-learn.org/0.19/datasets/olivetti_faces.html) is an image dataset. There are 10 different images of each of 40 distinct subjects. The image is quantized to 256 grey levels and stored as unsigned 8-bit integers. Below is the image containing all 400 samples.<br>\n",
    "<img src=\"olivettifaces.gif\" width=\"300\" height='151'>\n",
    "**olivettifaces** could be loaded by using sklearn.dataset packages. In this tutorial, in order to get familiarize with the image format, you are required to implement a `load_images()` function. It is used for loading the image file *olivettifaces.gif* and split it into data sets for train and test. <br>\n",
    "Each sample from *olivettifaces* is an image with 57 by 47 pixels. Therefore the images will be loaded into a 400 by 2679(57\\*47) array. The number of samples is 400, and each sample has a pixels/feature vector with size 2679. <br>\n",
    "For the learing purpose the data should be further split into: \n",
    "- `train_data`:        360 samples\n",
    "- `train_target`:      subject id (0-39) for samples from train_data \n",
    "- `test_data`:   40 samples\n",
    "- `test_target`: subject id for samples from validation_data \n",
    "\n",
    "*hint*: It'd be good that facial images for all subjects participate in training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load face image data\n",
    "def load_images(filename):\n",
    "\n",
    "    image = Image.open(filename) # load the image\n",
    "    data_imgs = np.asarray(image) # convert image to numpy array\n",
    "    image_trimmed = np.delete(data_imgs, [471, 472], 1) #trim the vertical white line of the image @ col 471 n 472\n",
    "    \n",
    "    final = np.zeros(2679).reshape((1, 2679)) # initialize final var for vstack ops\n",
    "    train_data = np.zeros(2679).reshape((1, 2679)) # initialize train_data for vstack ops\n",
    "    test_data = np.zeros(2679).reshape((1, 2679)) # initialize test_data for vstack ops\n",
    "\n",
    "    for imgs_in_a_row in np.vsplit(image_trimmed, 20): # split into 20 rows\n",
    "        faces_20 = np.hsplit(imgs_in_a_row, 20) #split into 20 columns\n",
    "        for each_face in faces_20: \n",
    "            face = np.reshape(each_face, (1, 2679))\n",
    "            final = np.vstack((final, face))\n",
    "    final = final[1:] # remove the initial zeros array\n",
    "    \n",
    "    for i in np.vsplit(final, 40):  # split final into 10 rows per i train and test\n",
    "        train_data = np.vstack((train_data, i[:9])) # for every 10, takes 9 as train data\n",
    "        test_data = np.vstack((test_data, i[-1])) # # for every 10, takes 1 as test data\n",
    "   \n",
    "    train_data = train_data[1:] # remove the initial zeros array\n",
    "    test_data = test_data[1:]   # remove the initial zeros array\n",
    "    ## ---------------------------------\n",
    "    train_target = np.zeros((360, ))  # create train_target labels\n",
    "    counter = 0 \n",
    "    for i in range(40):  \n",
    "        for j in range(9):\n",
    "            train_target[counter] = i \n",
    "            counter += 1\n",
    "    ## ---------------------------------\n",
    "    test_target = np.zeros((40, ))  # create test_target labels\n",
    "    counter = 0\n",
    "    for j in range(40):\n",
    "        test_target[counter] = j \n",
    "        counter += 1\n",
    "\n",
    "    return train_data, train_target, test_data, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 2679) (360,) (40, 2679) (40,)\n"
     ]
    }
   ],
   "source": [
    "# Get the data sets\n",
    "train_data, train_target, test_data, test_target = load_images(\"olivettifaces.gif\")\n",
    "print(train_data.shape, train_target.shape, test_data.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression\n",
    "We've learn Logistic Regresson in the previous part of this module. <br>\n",
    "You're to use the `LogisticRegression` function to trian a model on `train_data` and test if on the `test_data`. Type your code in the cell below, print out the accuracy on `train_data` and `test_data`. <br>\n",
    "See the page [ref](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to learn the use the learning algorithm. The key to success is the parater `solver` which gives options on different gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "# for s in ['lbfgs', 'sag', 'saga', 'newton-cg']:\n",
    "clf = LogisticRegression(solver='newton-cg', random_state=0)\n",
    "clf.fit(train_data, train_target)\n",
    "print(f'Test Score: {clf.score(test_data, test_target)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest\n",
    "\n",
    "Random forest is a supervised, ensemble learning method for classification or regression. For a classification problem, it constructs many decision trees at training time and  merges them together at testing time to get a more accurate and stable prediction. <br>\n",
    "\n",
    "In this task, use the `RandomForestClassifier` function to train the model on `train_data` and test if on the `test_data`. Type your code in the cell below, print out the accuracy on `train_data` and `test_data`. <br>\n",
    "See the page [ref](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to learn the use the learning algorithm. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.975\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "# Create the model with 100 trees\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=200, random_state=0)\n",
    "clf.fit(train_data, train_target)\n",
    "print(f'Test score: {clf.score(test_data, test_target)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Answer questions\n",
    "\n",
    "- 1. What is the logistic regression model for prediction/classification? How many parameters to be learnt? <br>\n",
    "Ans: Logistic regression is a statistical model that in its basic form uses a logistic function to model the probability of a certain class or event   existing in a binary sense, like 1 or 0, in our context. As above, each sample has a pixels/feature vector with size 2679, which corresponds to 2679 parameters to be learnt. \n",
    "\n",
    "    \n",
    "- 2. How does the Random Forest learning algorithm used for real-valued features? <br>\n",
    "Ans: Random forest onsists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our modelâ€™s prediction. Each tree in a random forest can pick only from a random subset of real-valued features. This forces even more variation amongst the trees in the model and ultimately results in lower correlation across trees and more diversification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
